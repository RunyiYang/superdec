seed: 42
use_wandb: true
wandb:
  project: superdec
  entity: elisabettafedele99
run_name: 10-07-debug #-sps-everywhere
dataset: shapenet  #shapenetOverfit 
device: cuda

checkpoints:
  resume_from: #/ephemeral/outputs/epoch_500.pt #/local/home/efedele/Programming/superdec/outputs/epoch_5.pt
  keep_epoch: False

superdec:
  decoder:
    n_queries: 16
    n_layers: 3 # number of transformer decoders
    n_heads: 1
    masked_attention: false
    swapped_attention: false
    dim_feedforward: 512 # default
    deep_supervision: False
    pos_encoding_type: sinusoidal
  point_encoder:
    in_channels: 3
    out_channels: 128
    kernel_size: 3
    resolution: 32
    voxelization:
      normalize: True
      eps: 0
    l1:
      in_channels: 3
      out_channels: 64
      kernel_size: 3
      resolution: 32
      voxelization:
        normalize: True
        eps: 0
    l2:
      in_channels: 64
      out_channels: 128
      kernel_size: 3
      resolution: 16
      voxelization:
        normalize: True
        eps: 0
    l3:
      in_channels: 128
      out_channels: 128
      kernel_size: 3
      resolution: 16
      voxelization:
        normalize: True
        eps: 0  

shapenet:
  path: data/ShapeNet
  categories: null #['03001627'] 
  normalize: False

trainer:
  save_path: /ephemeral/outputs
  save_every_n_epochs: 1
  num_epochs: 500
  batch_size: 4 #\16
  num_workers: 4
  evaluate_every_n_epochs: 1
  augmentations: True
optimizer:
  lr: 1e-4 #1e-4   0.001
  weight_decay: 0 # default
  betas: [0.9, 0.999] # default
  enable_scheduler: True

scheduler:  
  _target_: torch.optim.lr_scheduler.OneCycleLR 
  max_lr: ${optimizer.lr} 
  epochs: ${trainer.num_epochs}
  steps_per_epoch: -1

loss:
  n_samples: 500
  w_sps: 0.1 
  w_ext: 0.01 
  w_cub: 1.0 
  w_cd: 1.0
  
visualization:
  res_primitives: 40